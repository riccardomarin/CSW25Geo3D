{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSNX2DVa2YTd"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "\n",
        "! pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzCyb6qun4pw"
      },
      "source": [
        "Imports and Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ22ImB9xryu"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import nn\n",
        "import torch.nn.parallel\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.graph_objs import Layout\n",
        "from plotly.graph_objs import Layout\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from typing import Union, Sequence, Optional\n",
        "from torch.nn.functional import nll_loss\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "def plot3d(\n",
        "    x: Union[np.ndarray, torch.Tensor], c: Union[np.ndarray, torch.Tensor]\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Plot the function c over the point cloud x\n",
        "    \"\"\"\n",
        "    fig = go.Figure(\n",
        "        data=[\n",
        "            go.Scatter3d(\n",
        "                x=x[:, 0],\n",
        "                y=x[:, 1],\n",
        "                z=x[:, 2],\n",
        "                mode=\"markers\",\n",
        "                marker=dict(color=c, colorscale=\"viridis\", size=5, showscale=True),\n",
        "            )\n",
        "        ],\n",
        "        layout=Layout(scene=dict(aspectmode=\"data\")),\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "def plot3d_shapes(\n",
        "    x: Sequence[Union[np.ndarray, torch.Tensor]], c: Sequence[Union[np.ndarray, torch.Tensor]], subplot_titles: Optional[Sequence[str]] = None\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Plot the function c over the point cloud x\n",
        "    \"\"\"\n",
        "    fig = make_subplots(\n",
        "        rows=1,\n",
        "        cols=len(x),\n",
        "        specs=[[{\"is_3d\": True}] * len(x)],\n",
        "        horizontal_spacing=0,\n",
        "        vertical_spacing=0,\n",
        "        subplot_titles=subplot_titles if subplot_titles is not None else None,\n",
        "\n",
        "    )\n",
        "\n",
        "    myscene = dict(\n",
        "        camera=dict(\n",
        "            up=dict(x=0, y=1, z=0),\n",
        "            center=dict(x=0, y=0, z=0),\n",
        "            eye=dict(x=-0.25, y=0.25, z=2.75),\n",
        "        ),\n",
        "        aspectmode=\"data\",\n",
        "    )\n",
        "\n",
        "    for i, (points, color) in enumerate(zip(x, c)):\n",
        "      fig.add_trace(\n",
        "          go.Scatter3d(\n",
        "                x=points[:, 0],\n",
        "                y=points[:, 1],\n",
        "                z=points[:, 2],\n",
        "                mode=\"markers\",\n",
        "                marker=dict(color=color, colorscale=\"viridis\", size=5, showscale=True),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=i+1\n",
        "      )\n",
        "\n",
        "    for i in range(len(x)):\n",
        "      fig[\"layout\"][f\"scene{i+1}\"].update(myscene)\n",
        "\n",
        "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=30))\n",
        "\n",
        "    fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pESKJ49nn8QI"
      },
      "source": [
        "We just get some data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmGJ-65r1zLk"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "\n",
        "!wget -O 'data.zip' \"https://www.dropbox.com/sh/qzh9bo3rbpd0k7d/AAA_dUzVFHBBqLrS8qslYCMJa?dl=1\"\n",
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBmB8lK819uq"
      },
      "source": [
        "We define an appropriate data loader. Nothing special: it will provide us point clouds and the mask of their regions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xUdNJgM17Hj"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "class ShapeLocalizationDataset(Dataset):\n",
        "  def __init__(self, shapes_data_name: str , region_data_name: str):\n",
        "    super().__init__()\n",
        "    self.shapes_data_name = shapes_data_name\n",
        "    self.region_data_name = region_data_name\n",
        "\n",
        "    self.shapes = np.load(shapes_data_name).astype(np.float32)\n",
        "\n",
        "    self.region_idxs = np.loadtxt(region_data_name).astype(np.int64) - 1\n",
        "    self.mask = np.zeros(self.shapes.shape[1], dtype=np.int64)\n",
        "    self.mask[self.region_idxs] = 1\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return self.shapes.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx: int) -> Dict[str, np.ndarray]:\n",
        "    \"\"\" Returns the points of a point cloud with shape [n, 3] and the region\n",
        "    that must be localized with shape [n]\n",
        "    \"\"\"\n",
        "    shape = self.shapes[idx]\n",
        "    return {\n",
        "        'id': idx,\n",
        "        'points': shape,\n",
        "        'mask': self.mask\n",
        "    }\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"ShapeLocalizationDataset(shapes_data_name='{self.shapes_data_name}', region_data_name='{self.region_data_name}')\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVbuV9y91-0e"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "\n",
        "print(ShapeLocalizationDataset('2K_shapes_train.npy', 'head_idxs4template1K.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq1TgHnE2AbP"
      },
      "outputs": [],
      "source": [
        "#@title Explore data { run: \"auto\" } {vertical-output: true}\n",
        "shapes_data = \"12k_shapes_train.npy\" #@param [\"12k_shapes_test.npy\", \"2K_shapes_train.npy\", \"12k_shapes_train.npy\", \"200_shapes_test.npy\"]\n",
        "region_data = \"head_idxs4template1K.txt\" #@param [\"head_idxs4template1K.txt\", \"belly_idxs4template1K.txt\"]\n",
        "sample_idx = 33 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "\n",
        "\n",
        "dataset = ShapeLocalizationDataset(shapes_data_name=shapes_data, region_data_name=region_data)\n",
        "\n",
        "sample = dataset[sample_idx]\n",
        "plot3d(sample['points'], sample['mask'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ00IGVD2OUY"
      },
      "source": [
        "# Setup data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiUnV5352NOV"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "# Decide with data to use\n",
        "shapes_data_train = \"12k_shapes_train.npy\"\n",
        "shapes_data_test = \"12k_shapes_test.npy\"\n",
        "region_data = \"head_idxs4template1K.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcXBRcRroJhd"
      },
      "source": [
        "We create the data loader for training and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C3IVGjd2C4-"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "\n",
        "train_dataset = ShapeLocalizationDataset(shapes_data_name=shapes_data_train, region_data_name=region_data)\n",
        "test_dataset = ShapeLocalizationDataset(shapes_data_name=shapes_data_test, region_data_name=region_data)\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 16\n",
        "num_workers = 2  # number of parallel processes to use to prepare batches\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdFNhZmPoSE2"
      },
      "source": [
        "Let's visualize how a data batch looks like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8BOACZD2V2Y"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "for batch in train_dataloader:\n",
        "  print(batch)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUkel63f2-pt"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "\n",
        "class STN3d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(STN3d, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 9)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.bn4 = nn.BatchNorm1d(512)\n",
        "        self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "\n",
        "        x = F.relu(self.bn4(self.fc1(x)))\n",
        "        x = F.relu(self.bn5(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        iden = Variable(torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32))).view(1,9).repeat(batchsize,1)\n",
        "        if x.is_cuda:\n",
        "            iden = iden.cuda()\n",
        "        x = x + iden\n",
        "        x = x.view(-1, 3, 3)\n",
        "        return x\n",
        "\n",
        "\n",
        "class STNkd(nn.Module):\n",
        "    def __init__(self, k=64):\n",
        "        super(STNkd, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, k*k)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.bn4 = nn.BatchNorm1d(512)\n",
        "        self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "\n",
        "        x = F.relu(self.bn4(self.fc1(x)))\n",
        "        x = F.relu(self.bn5(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1,self.k*self.k).repeat(batchsize,1)\n",
        "        if x.is_cuda:\n",
        "            iden = iden.cuda()\n",
        "        x = x + iden\n",
        "        x = x.view(-1, self.k, self.k)\n",
        "        return x\n",
        "\n",
        "class PointNetfeat(nn.Module):\n",
        "    def __init__(self, global_feat = True, feature_transform = False):\n",
        "        super(PointNetfeat, self).__init__()\n",
        "        self.stn = STN3d()\n",
        "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.global_feat = global_feat\n",
        "        self.feature_transform = feature_transform\n",
        "        if self.feature_transform:\n",
        "            self.fstn = STNkd(k=64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_pts = x.size()[2]\n",
        "        trans = self.stn(x)\n",
        "        x = x.transpose(2, 1)\n",
        "        x = torch.bmm(x, trans)\n",
        "        x = x.transpose(2, 1)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        if self.feature_transform:\n",
        "            trans_feat = self.fstn(x)\n",
        "            x = x.transpose(2,1)\n",
        "            x = torch.bmm(x, trans_feat)\n",
        "            x = x.transpose(2,1)\n",
        "        else:\n",
        "            trans_feat = None\n",
        "\n",
        "        pointfeat = x\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.bn3(self.conv3(x))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "        if self.global_feat:\n",
        "            return x, trans, trans_feat\n",
        "        else:\n",
        "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
        "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
        "\n",
        "\n",
        "class PointNetDenseCls(nn.Module):\n",
        "    def __init__(self, k = 2, feature_transform=False):\n",
        "        super(PointNetDenseCls, self).__init__()\n",
        "        self.k = k\n",
        "        self.feature_transform=feature_transform\n",
        "        self.feat = PointNetfeat(global_feat=False, feature_transform=feature_transform)\n",
        "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
        "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        n_pts = x.size()[2]\n",
        "        x, trans, trans_feat = self.feat(x)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.conv4(x)\n",
        "        x = x.transpose(2,1).contiguous()\n",
        "        x = F.log_softmax(x.view(-1,self.k), dim=-1)  # do not use crossentropy\n",
        "        x = x.view(batchsize, n_pts, self.k)\n",
        "        return x, trans, trans_feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixyBYJbj3UCq"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "\n",
        "class RegionLocalizationModule(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    k = 2\n",
        "    self.pointnet = PointNetDenseCls(k=k, feature_transform=True)\n",
        "\n",
        "    self.train_accuracy = torchmetrics.Accuracy(task='multiclass',num_classes=k)\n",
        "    self.test_accuracy = torchmetrics.Accuracy(task='multiclass',num_classes=k)\n",
        "\n",
        "  def forward(self, points: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Defines the behaviour in the forward pass\n",
        "\n",
        "    Args:\n",
        "      points: shape points with shape [batch, xyz, num_points]\n",
        "\n",
        "    Returns:\n",
        "      probability distributions over the classes for each point [batch, xyz, k]\n",
        "    \"\"\"\n",
        "    points = points.transpose(1, 2)\n",
        "    out, _, _ = self.pointnet(points)\n",
        "    return out\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    \"\"\"\n",
        "    Defines the training logic\n",
        "    \"\"\"\n",
        "    points = batch['points']\n",
        "    y = batch['mask']\n",
        "\n",
        "    y_pred = self(points)\n",
        "\n",
        "\n",
        "    y_pred = y_pred.transpose(1, 2)\n",
        "    loss = nll_loss(y_pred, y)\n",
        "\n",
        "    self.train_accuracy(y_pred.exp(), y)\n",
        "\n",
        "    self.log_dict({'train_loss': loss, 'train_acc': self.train_accuracy}, on_step=True, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    \"\"\"\n",
        "    Defines the training logic\n",
        "    \"\"\"\n",
        "    points = batch['points']\n",
        "    y = batch['mask']\n",
        "\n",
        "    y_pred = self(points)\n",
        "\n",
        "\n",
        "    y_pred = y_pred.transpose(1, 2)\n",
        "    loss = nll_loss(y_pred, y)\n",
        "\n",
        "    self.test_accuracy(y_pred.exp(), y)\n",
        "\n",
        "    self.log_dict({'test_loss': loss, 'test_acc': self.test_accuracy}, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    \"\"\"\n",
        "    Configure optimizers\n",
        "    \"\"\"\n",
        "    return torch.optim.AdamW(self.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvBWxzOb3Xdl"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "# Instantiate the model\n",
        "model = RegionLocalizationModule()\n",
        "\n",
        "# Instantiate the trainer\n",
        "trainer = pl.Trainer(accelerator=\"auto\", max_steps=5000, max_epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SefF6TdTo17J"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "results = trainer.test(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FAAuYdp3af1"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "# Train the model\n",
        "trainer.fit(model, train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh-ayViH3dxC"
      },
      "outputs": [],
      "source": [
        "#@title {vertical-output: true}\n",
        "results = trainer.test(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EdYXEIlC3luy"
      },
      "outputs": [],
      "source": [
        "#@title Explore predictions { run: \"auto\" }\n",
        "shapes_data = \"12k_shapes_test.npy\" #@param [\"12k_shapes_test.npy\", \"200_shapes_test.npy\"]\n",
        "region_data = \"head_idxs4template1K.txt\" #@param [\"head_idxs4template1K.txt\", \"belly_idxs4template1K.txt\"]\n",
        "dataset = ShapeLocalizationDataset(shapes_data_name=shapes_data, region_data_name=region_data)\n",
        "\n",
        "sample_idx = 920 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "permute_points = True #@param {type:\"boolean\"}\n",
        "sample_points = True #@param {type:\"boolean\"}\n",
        "number_of_sampled_points = 494 #@param {type:\"slider\", min:5, max:1000, step:1}\n",
        "\n",
        "model = model.cpu()\n",
        "model.eval()\n",
        "\n",
        "if sample_idx > len(dataset):\n",
        "  print(f'Sample idx over the selected dataset length. Setted to : {len(dataset)}')\n",
        "  sample_idx = len(dataset) - 1\n",
        "\n",
        "# [1, n_points, xyz]\n",
        "points = torch.from_numpy(dataset[sample_idx]['points'])[None, ...]\n",
        "\n",
        "y = dataset[sample_idx]['mask']\n",
        "\n",
        "\n",
        "if permute_points:\n",
        "  perm_points = torch.randperm(1000)\n",
        "  points = points[:, perm_points, :]\n",
        "  y = y[perm_points]\n",
        "\n",
        "if sample_points:\n",
        "  points_to_keep = torch.randperm(1000)[:number_of_sampled_points]\n",
        "  points = points[:, points_to_keep, :]\n",
        "  y = y[points_to_keep]\n",
        "\n",
        "\n",
        "# [1, n_points, k]\n",
        "y_pred = model(points)\n",
        "\n",
        "# [n_points]\n",
        "y_pred = y_pred.argmax(-1).squeeze(0)\n",
        "\n",
        "\n",
        "plot3d_shapes([points[0], points[0]], [y, y_pred], ['Ground truth', 'Prediction'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}